# Mature Microservices and How to Operate Them

* It's hard to operate microservices
    * Microservices allow for any tech choice
        * Knowledge requirements much higher across estate
        * How do you backup *this* database??
    * Lots of microservices across lots of teams
        * Where is a given problem happening?
        * Who can fix it?
    * Your next legacy systems will likely be Microservices!
* Why bother with microservices?
    * FT.com - organisation needs to be abe to experiment with new revenue models
    * Most experiments end up as prod because of the sunk cost fallacy
        * So experiments must be cheap!
        * CD, DevOps, Microservices enable this.
* Optimising for speed
    * Delivery Lead Time
        * less than 1h
    * Delivery Frequency
        * *"If it hurts, do it more frequently, and bring the pain forward"*
    * CD
        * Automated build and release pipeline
        * Automated testing integrated into the pipeline
    * CI
        * Even with CD you should be getting changes out straight away
        * No point having CD and releasing once per week
    * Architecture
        * Some architecture does not allow for zero-downtime deployments etc
        * Sequential deployments
        * Schemaless databases
    * Test and deploy changes independently
    * Systems and teams need to be loosely coupled
        * No need to release services in a group
        * Microservices make it easier to remain uncoupled so they help with this
        * Coordinating between teams slows you down
    * Process Theatre needs to be eliminated
    * Usually fix and roll forward rather than roll back
* Operating Microservice
    * Transaction and data consistency problems
    * DevOps practices
        * The team that builds the system *has* to operate it too.
        * You can't afford the cost of coordination
        * High performing teams get to make their own decisions about tools + tech
            * You don't want to have to wait for an architecture team to make decisions
            * This makes it hard for any central teams to coordinate anything
        * Make *everything* someone else's problem (use SaaS, Cloud services etc)
            * Buy rather than build unless it is *critical to your business*
    * Accept that you will generally be in a state of "grey failure"
        * Expect transient things to happen
        * Backoff and retry
        * Be willing to Mitigate Now, Fix Tomorrow
    * How do you know something's wrong?
        * Concentrate on the business capabilites
            * Monitor based on this: e.g. "can we publish the news?"
                * Synthetic monitoring: e.g. publish an old article and ensure that it's published
                * Means we always expect articles to be published: can alert if nothing is.
                * What does it mean for a publish to be "successful"?
                    * On publish, notification goes to Publish Monitor
                    * Publish monitor checks that the article is published everywhere
    * Build observability into the system
        * Infer what's going on in the system by observing its outputs
            * Log the stuff that's interesting
            * Tie logs together via unique ID
                * Transaciton ID added to header
                * Must be passed on to every service
                * Zipkin
        * Metrics
            * Concentrate on the layer that's closest to the customer
                * Request rate
                * Error rate
                * Duration
        * You'll always be concentrating on *something*
            * Doing things 150 times over is slow and painful
            * Things like deployment pipelines need to be templated
            * Use a service mesh
                * Discovery
                * Routing
                * Fialure / Recovery
                * You can concentrate on the Business Logic
* When people move on
    * Every system must be owned by a team!
        * Team might not overtly adopt immediately
        * If you won't invest enough to keep it running properly, shut it down
        * Assume that there is an amount of work on every system that exists: include it in TCO.
    * Keeping docs up to date is a challenge
        * Much harder for microservices
            * More services
            * Lots of duplication
        * A graph works well
            * E.g. when someone changes role, just change it in one place.
            * Visualise relationships
            * Understand costs related to decommissioned systems etc
        * A unique system code for every system!!!
            * Can identify the system everywhere
        * Give people something in return
            * Centralised monitoring
            * Multiple systems -> Prometheus
            * Automatically provide dashboards based on the data generated by the system
            * Keep runbooks as `RUNBOOK.md` in the repo
                * Hook it into a change API
            * System operability score
                * Teams get a score: gamifies improvement!
                * Final manual review required
            * Auto technology risk dashboarding
    * Practice
        * Failover weekly for practice
        * Chaos engineering
            * Understand your steady state
            * Look at what you can change - minimise the blast radius
            * Work out what you expect to see happen
            * Run the experiment and see if you were right.
* Building and opeating microservices is hard work.
    * You have to maintain knowledge of live services
    * Plan now for future legacy microservices
    * Only worth the pain if you are moving fast
* Book
    * Accelerate - The Science of DevOps
    * Continuous Delivery
    * medium.com/wardelymaps

* Transient issues
    * Dashboards aren't watched.
    * How do you decide when to proactively alert? Signal vs noise?
